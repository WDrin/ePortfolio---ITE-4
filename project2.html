<div style="position: fixed; top: 10px; right: 10px;">
    <button onclick="goBack()"
        style="padding: 10px 20px; background-color: #444; color: #ffffff; border: none; border-radius: 5px; cursor: pointer;">
        Back
    </button>
</div>

<script>
    function goBack() {
        window.history.back();
    }
</script>
<div class="container">
    <!-- Header Section -->
    <header
        style="position: fixed; top: 0; left: 0; right: 0; background-color: #000000; padding: 15px; display: flex; justify-content: space-between; align-items: center; box-shadow: 0 2px 5px rgba(0,0,0,0.1); z-index: 1000;">
        <h1 style="color: #ffffff;">Midterm Activities</h1>
        <button onclick="goBack()"
            style="padding: 10px 20px; background-color: #444; color: #808080; border: none; border-radius: 5px; cursor: pointer;">
            Back
        </button>
    </header>

    <!-- Adjust container margin to account for fixed header -->
    <div class="container" style="margin-top: 80px;">
        <!-- Term Activities Section -->
        <section class="term-activities">
            <div class="term-description">
                <p style="color: #ffffff;">The midterm term was a valuable phase of learning that strengthened my
                    technical skills, broadened my understanding of NLP applications, and highlighted the importance of
                    data quality, model selection, and structured workflows. Through various tasks, I gained deeper
                    insights into how theoretical concepts translate into practical implementations.<br><br>

                    The midterm term was a period of improvement development. In the short term, I aim to refine my
                    skills
                    in model tuning and data processing. My long-term goal is to develop expertise in applying NLP and
                    AI technologies to create innovative solutions for complex challenges. This term has solidified my
                    foundation and inspired me to continue advancing in the field of natural language processing.
                </p>
            </div>
            <div class="activities-grid">
                <div class="activity-card">
                    <h3 style="color: #ffffff;">Exercise M1 - Implementing NLP Application Models using Spacy</h3>
                    <div class="exam-score">
                        <p style="font-size: 1.2em; margin-top: 15px; color: #ffffff;">Grade: <span
                                style="color: #4CAF50; font-weight: bold;">75</span></p>
                    </div>
                    <p style="color: #ffffff;">The file is well organized and contains a complete set of outputs, each
                        labeled by descriptive captions that clarify the purpose and significance of the content
                        presented. These detailed annotations enhance understanding, allowing readers to appreciate the
                        individual contributions of each item in relation to the overall project.<br><br>

                        Additionally, this structured documentation highlights the broader goals and objectives of the
                        project, making it easier to see how each component fits into the larger framework. The complete
                        organization of the file significantly facilitates the review process, enabling both the author
                        and the readers to track progress over time efficiently. This layout not only enhances
                        clarity but also facilitates a deeper comprehension of the importance of each item, ensuring
                        that every aspect is recognized for its role in achieving the project's aims.

                    </p>
                    <div class="file-link">
                        <a href="https://drive.google.com/file/d/1x_6dfvLEfq3XFH160G6qBUrWBLURHge-/view?usp=sharing"
                            target="_blank" style="display: inline-block; padding: 5px 10px; margin-top: 10px; 
                                  background-color: #444; color: #ffffff; border: none; 
                                  border-radius: 3px; cursor: pointer; text-decoration: none;">
                            View Project Files
                        </a>
                    </div>
                </div>
                <!-- Add more activity cards as needed -->
            </div>
        </section>

        <!-- Personal Reflection Panel -->
        <section class="reflection-panel">
            <h2 style="color: #ffffff;">Personal Reflection</h2>
            <div class="reflection-content">
                <p style="color: #ffffff;">My reflection on this activity is for creating detailed and organized
                    documentation for complex projects. It showcases my progress in NLP annotation and my ability to
                    present data in a clear and accessible manner. Throughout this project, I not only enhanced my
                    technical skills but also improved my capacity to annotate outputs with precision and purpose. A
                    significant achievement highlighted here is my ability to align each annotation with a broader
                    learning objective, ensuring that every step contributes meaningfully to my overall growth.
                    <br><br>
                    As I move forward, my short-term objective is to refine my annotation process by including
                    feedback. In the long term, I aim to enhance my ability in NLP and annotation tools to reach a
                    higher level of expertise and efficiency in future projects.
                </p>
            </div>
        </section>

        <!-- Peer Reviews Section -->
        <section class="peer-reviews">
            <h2 style="color: #ffffff;">Peer Reviews</h2>
            <div class="review-panels">
                <!-- Review Panel 1 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 1</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Sep 22 at 1:48pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The work focuses on key Nlp tasks such as POS
                            tagging, sentiment analysis, and text summarization. The POS tagging section
                            uses spacy to analyze a given input text and label each token with its
                            corresponding POS tag, demonstrating a basic application of linguistic
                            analysis. For sentiment analysis, the notebook sets up a sentiment classifier that
                            categorizes text as "POSITIVE" or "NEGATIVE" based on a small dataset. While the
                            implementation shows how to define and train a basic sentiment model using spacy, the
                            dataset is very limited, which might affect the accuracy and generalizability of the
                            model. Expanding the dataset and incorporating performance evaluation metrics would
                            strengthen this section. In summary, the notebook provides a straightforward
                            introduction to essential NLP tasks using spacy. While the implementations are
                            functional, they would benefit from more extensive datasets, evaluation methods, and
                            additional explanations to enhance the effectiveness and clarity of the tasks.</p>
                    </div>
                </div>

                <!-- Review Panel 2 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 2</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Sep 23 at 12:08am</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The student's work was able to correctly follow the required
                            formatting for each markdown cell comment, which also contained well structured explanations
                            for the lines of code that each was providing an observation and explanation towards.
                            Providing numerical representations for the code's flow was also a good addition as it
                            implies a decent grasp on the events occurring in a chronological order.</p>
                    </div>
                </div>

                <!-- Review Panel 3 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 3</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Sep 23 at 11:13am</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">Upon reviewing your notebook, I found the approach to NLP annotation
                            well-structured and logically presented. Additionally, the inclusion of references was a
                            strong choice, as it adds credibility and offers resources for further reading, which is
                            beneficial for those looking to dive deeper into the subject. Overall, the notebook is
                            highly informative and demonstrates an impressive depth of understanding of the material.
                            Your structured approach and thoughtful inclusion of references showcase a mastery of the
                            subject. By providing even more elaboration on the reasoning behind key decisions and
                            incorporating additional examples, this already excellent work could become an essential
                            resource for a reader, further amplifying its impact and value.</p>
                    </div>
                </div>
            </div>

        </section>
        <br>
        <br>
        <!-- Task 2 Section -->
        <section class="term-activities">
            <div class="activities-grid">
                <div class="activity-card">
                    <h3 style="color: #ffffff;">Exercise M1.1 - Evaluating NLP Model Performance</h3>
                    <div class="exam-score">
                        <p style="font-size: 1.2em; margin-top: 15px; color: #ffffff;">Grade: <span
                                style="color: #4CAF50; font-weight: bold;">75</span></p>
                    </div>
                    <p style="color: #ffffff;">The activity offers a thorough analysis of the performance of
                        natural language processing (NLP) models trained on low-quality, small-sized datasets across
                        a range of NLP tasks. These tasks encompass text classification, named entity recognition
                        (NER), part-of-speech (POS) tagging, sentiment analysis, and text summarization. It assesses
                        each model's performance by detailing the methodologies employed and the metrics used,
                        including accuracy, precision, recall, and F1 scores, while addressing the challenges related to
                        limited data quality.
                        <br><br>
                        The document highlights the necessity of high-quality training data and explores advanced
                        techniques, such as data enlargement and transfer learning, to enhance model accuracy and
                        reliability.
                    </p>

                    <!-- Document Link Section (replaced upload section) -->
                    <div class="file-link">
                        <a href="https://drive.google.com/drive/folders/1SmNasUN8Ec5w0rQz3-4rmKtytsaix6GN?usp=sharing"
                            target="_blank" style="display: inline-block; padding: 5px 10px; margin-top: 10px; 
                                  background-color: #444; color: #ffffff; border: none; 
                                  border-radius: 3px; cursor: pointer; text-decoration: none;">
                            View Project Files
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <!-- Task 2 Personal Reflection -->
        <section class="reflection-panel">
            <h2 style="color: #ffffff;">Personal Reflection</h2>
            <div class="reflection-content">
                <p style="color: #ffffff;">My reflection on this activity highlights my growth in understanding the
                    critical relationship between data quality and model performance in NLP. Through this exercise, I
                    improved my skills in training and evaluating models, especially regarding the limitations of
                    models trained on limited datasets. This experience highlighted the importance of robust data for
                    successful NLP applications and motivated me to pursue further learning in optimizing data quality
                    and employing advanced training methods.
                    <br><br>
                    In the short term, my goal is to experiment with larger, diverse datasets to improve model
                    accuracy. In the long term, I aim to deepen my expertise in NLP and machine learning frameworks to
                    enhance my model-building capabilities, enabling more accurate and efficient applications across
                    diverse language processing tasks.
                </p>

            </div>
        </section>

        <!-- Task 2 Peer Reviews -->
        <section class="peer-reviews">
            <h2 style="color: #ffffff;">Peer Reviews</h2>
            <div class="review-panels">
                <!-- Review Panel 1 -->
                <div class="review-card">
                    <Peer style="color: #ffffff;">Peer Review 1</h3>
                        <div class="reviewer-info">
                            <p class="review-date" style="color: #ffffff;">Date: Sep 28 at 5pm</p>
                        </div>
                        <div class="review-content">
                            <p style="color: #ffffff;">The performance of the five subsets in different NLP models was
                                presented well in the work of Mr. Rayos Del Sol in the document file. He was able to
                                select the correct information and claim relevant data, as well as derive a useful
                                conclusion. A spreadsheet was also provided, which contained all models accompanied by
                                their performance and extra columns. That is one area that should have been enhanced,
                                that is, adding annotations in the Google Colab notebook. He stated explanations in the
                                document accompanied with annotations to aid understanding certain segments of codes
                                employed for the machine learning would prove of benefit.
                                <br><br>

                                Also, there are differences in the text fonts and format within the document compared to
                                the template. The template shows how this could result in improving the uniformity of
                                the work itself.
                            </p>
                        </div>
                </div>

                <!-- Review Panel 2 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 2</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Sep 29 at 6:44pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">In this activity the first thing that I notice is that the researcher
                            did not follow the IEEE format for this subject. Also the dataset that been use is all small
                            dataset as anything less than 200 or 1000 data is considered as small dataset. Returning to
                            the paper, the introduction is executed it introduce the different models. Next is the
                            methodology it explains the code used for each models. The results is lacking as it did not
                            show the difference of the small, medium and large - low and high quality data subset.
                            <br><br>
                            Next is the excel file the result is good but inconsistent some tiems it does not shows the
                            difference between low and high quality data. high quality data sometimes perform worse than
                            the low uqality data.
                        </p>
                    </div>
                </div>

                <!-- Review Panel 3 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 3</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Oct 5 at 3:30pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">In Mr. Rayos del Sol's work, he explores tasks like Text
                            Classification, Named Entity Recognition (NER), Part of Speech Tagging, Sentiment Analysis,
                            and Text Summarization with datasets that in different sizes and preprocessing complexity.
                            The results clearly show that the models had trouble with lower accuracy and other key
                            scores. Mr. Rayos del Sol explains his methodology, providing the code with explanation for
                            easy understanding. He explained how he prepared the data, built the models, and trained
                            them, making sure to explain the step during the process. He shows how the models were
                            improved through repeated training and explains how he measured their performance. His
                            analysis makes it easy to see why the models didn't work well, as he directly connects these
                            issues to the poor quality of the training data. By explaining everything clearly, he shows
                            why good, varied data is so important for training models that work well. Improved training
                            data is essential for creating more efficient natural language processing (NLP) models, as
                            demonstrated by Mr. Rayos del Sol's work, which is easily comprehensible.</p>
                    </div>
                </div>
            </div>
        </section>
        <br>
        <br>
        <!-- Task 3 Section -->
        <section class="term-activities">
            <div class="activities-grid">
                <div class="activity-card">
                    <h3 style="color: #ffffff;">Exercise 5 - (BERT-based QnA System)</h3>
                    <div class="exam-score">
                        <p style="font-size: 1.2em; margin-top: 15px; color: #ffffff;">Grade: <span
                                style="color: #4CAF50; font-weight: bold;">70</span></p>
                    </div>
                    <p style="color: #ffffff;">This file presents in a detailed exploration of a BERT-based
                        question-answering (QA) system that evaluates the performance of four distinct BERT models on
                        a set of predefined questions. The models analyzed
                        deepset/bert-large-uncased-whole-word-masking-squad2,
                        deepset/bert-medium-squad2-distilled, deepset/bert-base-cased-squad2, and
                        deepset/bert-base-uncased-squad2,
                        each possess unique attributes that affect their performance in terms of accuracy, speed, and
                        sensitivity to casing.
                        By feeding identical questions to each model, the document compares the models’ ability to
                        accurately identify answers,
                        the processing time required, and the certainty levels (probability scores) of their responses.
                        For instance, the
                        deepset/bert-large-uncased model displayed the highest accuracy and probability scores,
                        reflecting its strength in
                        complex question contexts, while the smaller deepset/bert-medium-squad2-distilled model provided
                        faster but slightly less accurate responses, suited for applications where speed is
                        prioritized.
                        <br><br>
                        The document highlights the sufficient role of casing sensitivity, with the cased models
                        performing better in identifying proper nouns and specific names, making them ideal for tasks
                        where such distinctions are critical. This structured approach not only enables a detailed
                        comparison but also highlights the importance of selecting a model based on the specific
                        accuracy, speed, and contextual needs of a QA application.
                    </p>

                    <div class="file-link">
                        <a href="https://drive.google.com/drive/folders/16l5D6NL7MKWxsz7DzXg2gdQ3g9ZlQDun?usp=sharing"
                            target="_blank" style="display: inline-block; padding: 5px 10px; margin-top: 10px; 
                              background-color: #444; color: #ffffff; border: none; 
                              border-radius: 3px; cursor: pointer; text-decoration: none;">
                            View Project Files
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <!-- Task 3 Personal Reflection -->
        <section class="reflection-panel">
            <h2 style="color: #ffffff;">Personal Reflection</h2>
            <div class="reflection-content">
                <p style="color: #ffffff;">This exercise allowed me to explore the complexities of deploying different
                    models for question-answering (QA) tasks and involves the balance between how accurate a model is
                    and how fast it works. Working with various BERT models provided insights into how factors like
                    model size, casing sensitivity, and pretraining affect QA performance, particularly for
                    applications that require a balance between speed and precision. Throughout this activity, I gained
                    a deeper understanding of the important considerations in selecting the right model for specific
                    use cases, emphasizing how model architecture and parameter tuning effect the overall performance.
                    <br><br>
                    My short-term goal is to enhance my skills in configuring models based on contextual needs. In the
                    long term, I aim to research advanced fine-tuning techniques to improve model versatility and
                    accuracy for complex QA tasks in real-world scenarios.
                </p>
            </div>
        </section>

        <!-- Task 3 Peer Reviews -->
        <section class="peer-reviews">
            <h2 style="color: #ffffff;">Peer Reviews</h2>
            <div class="review-panels">
                <!-- Review Panels (x3) -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 1</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Oct 8 at 10:53pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The paper of Mr. RayosdelSol explains what is question and answering
                            model is and provides a comparison of BERT based models for the Q&A system but is hindered
                            by frequent grammatical errors, redundancies, and unclear sentence structures that make it
                            difficult to follow. In some sections of the paper like for the introduction part, he does
                            not explain the importance of Q&A model training. The paper could be improved if he added
                            more information about the topic. It would also be better if he added a citation about the
                            model that he used throughout the experimentation as well as the dataset that he used. In
                            the result section of the paper, he just mentioned the model that got the highest and lowest
                            results and did not include the other two models. I think the result section could be better
                            if he included an image or just put the actual number of the probability or the accuracy
                            that he mentioned so that the reader can follow what he explained. Lastly, the format for
                            the IEEE paper is not followed, there are no keywords after the abstract. No explanation in
                            the .ipynb file.</p>
                    </div>
                </div>

                <!-- Review Panel 2 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 2</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Oct 17 at 6:34pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">Looking at this student's ipynb Notebook file I noticed that he was
                            able to run all codes and followed instructions except adding markdown cell comments in each
                            and every code to explain what he understands from the code and how it exactly works. Moving
                            on to his IEEE document, It's clear that the student followed the IEEE format in doing his
                            documentation and was able to input all the models he used but is missing something which is
                            the figures of codes he used in the IPYNB that could've been used as context as to what he's
                            explaining in the methodology. As for the excel file I don't have any comments as he
                            followed instructions correctly in it.</p>
                    </div>
                </div>


            </div>
        </section>
        <br>
        <br>

        <!-- Task 4 Section -->
        <section class="term-activities">
            <div class="activities-grid">
                <div class="activity-card">
                    <h3 style="color: #ffffff;">P-M1 (Project Proposal Presentation)</h3>

                    <p style="color: #ffffff;">This document is a research proposal from Group Shiminet, which includes
                        members Castillo, Manabat, and Rayos del Sol. The project aims to develop an AI-driven academic
                        companion designed to enhance the study processes for students by automating the generation
                        of educational resources. Specifically, the goal is to create a platform that utilizes
                        natural language processing (NLP) models to automatically generate summaries, flashcards, and
                        quizzes from textbook materials.
                        <br><br>
                        The proposal outlines the educational challenges students face, such as difficulties in
                        organizing and reviewing lecture notes, which often result in inefficient study habits. By
                        utilizing transformer-based NLP models, like BERT for summarization and GPT for generating
                        coherent content, the platform seeks to improve both the efficiency and effectiveness of
                        student learning.
                        <br><br>
                        Additionally, the document details the project's objectives, which include summarizing
                        lengthy texts, extracting key terms for flashcard generation, and creating quizzes aligned
                        with core concepts. The methodology section explains the selection of pre-trained models,
                        hyperparameter tuning, and data preprocessing steps. Anticipated challenges, such as handling
                        large volumes of data, processing complex educational language, and ensuring content
                        relevance, are also addressed.
                    </p>

                    <div class="file-link">
                        <a href="https://drive.google.com/drive/folders/1s8MBiF8uLtjfdoK-kjSJwoQ09HR6_SWb?usp=sharing"
                            target="_blank" style="display: inline-block; padding: 5px 10px; margin-top: 10px; 
                              background-color: #444; color: #ffffff; border: none; 
                              border-radius: 3px; cursor: pointer; text-decoration: none;">
                            View Project Files
                        </a>
                    </div>
                </div>
            </div>
        </section>

        <!-- Task 4 Personal Reflection -->
        <section class="reflection-panel">
            <h2 style="color: #ffffff;">Personal Reflection</h2>
            <div class="reflection-content">
                <p style="color: #ffffff;">This project allowed our group to deepen our understanding of natural
                    language processing (NLP) applications in educational technology, enhancing our skills in designing
                    and implementing AI solutions. Developing this proposal required us to analyze the suitability of
                    various NLP models for different tasks, which sharpened our abilities in model selection and
                    adaptation to real-world scenarios. Additionally, this project helped us recognize the challenges
                    associated with data preprocessing and quality control critical skills for future AI projects. 
                    <br><br>
                    For the short-term goal is to experiment with fine-tuning pre-trained models for the specific
                    educational tasks we outlined. In the long term, we aim to build a fully functional prototype
                    that can be tested and refined based on student feedback, ultimately contributing to a more
                    efficient learning experience.
                </p>
            </div>
        </section>

        <!-- Task 4 Peer Reviews -->
        <section class="peer-reviews">
            <h2 style="color: #ffffff;">Peer Reviews</h2>
            <div class="review-panels">
                <!-- Review Panels (x3) -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 1</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Oct 15 at 10:44pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The project proposal of Shiminet is an innovative idea in
                            transforming the way how students engage with educational materials that outline a
                            comprehensive plan for an AI powered academic companion tool that can automatically generate
                            a summary of papers or books I think as well as the flashcards, and quizzes to provide a
                            more efficient and effective reviewing. I think this approach is difficult to do since it's
                            AI and even though we say that using BERT and GPT and then fine tuned these models for
                            specific education contexts, it's not a small task as it involves handling large volumes of
                            data. In short, creating this proposal could be challenging as it requires a lot of training
                            and evaluation methods but if they executed it well this project could be a game changer for
                            personalized learning. The
                            paper could be improved if they provided more information about their data collection as
                            well as providing an explanation in the timeline of the study. They use the Gantt chart but
                            do not explain how well they will going to execute those phases in a timely manner.</p>
                    </div>
                </div>

                <!-- Review Panel 2 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 2</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Oct 22 at 8:42pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The proposal paper by the group Shiminet follows the correct format
                            based on the instructions. Their proposed project addresses a significant issue in
                            education, and the domain and specific problem are well explained in the introduction.
                            However, the specific problem is not just limited to students but it also apllies to the
                            teachers who make quizzes and flashcard for their students, solving their issue of making
                            those from the scratch. I like how they explain their chosen models and metrics by providing
                            both the rationale and advantages, which greatly support their proposal. This kind of
                            approach, I think is better compared to other papers that only define their models and
                            metrics without further justification. Overall, the paper demonstrates a good understanding
                            of the NLP tasks they want to do. However, considering the limited time for the project to
                            complete, they might consider removing the flashcard generation. If what I think about
                            generating flashcard is right, then their system will be generating images for flashcards,
                            and that could become a challenging and time-consuming task to make.</p>
                    </div>
                </div>

                <!-- Review Panel 3 -->
                <div class="review-card">
                    <h3 style="color: #ffffff;">Peer Review 3</h3>
                    <div class="reviewer-info">
                        <p class="review-date" style="color: #ffffff;">Date: Nov 2 at 10:35pm</p>
                    </div>
                    <div class="review-content">
                        <p style="color: #ffffff;">The proposal's goals are clearly stated in relation to the problem
                            that has been recognized the suggested solution will build NLP models that take complex
                            information and condense it using summaries, flashcards, and quizzes for important ideas.
                            Transformer-based models like BERT and GPT are specified under the well-developed technique
                            section. GPT works well for making logical questions and flashcards, whereas BERT's
                            contextual analysis is perfect for summarizing. Although taking into account all the
                            different themes and the associated terminology in educational materials may make it
                            difficult to extract constant accuracy, this combination of models seems to be very well
                            justified for the goals and appropriate for the topics.
                        </p>
                    </div>
                </div>
                <!-- Add 2 more review cards -->
            </div>
        </section>
        <br>
        <br>
        <!-- Midterm Exam Section -->
        <section class="activity-card">
            <h2 style="color: #ffffff;">Midterm Exam Performance</h2>
            <div class="exam-details">
                <h3 style="color: #ffffff;">Personal Reflection</h3>
                <p style="color: #ffffff;">For the midterm exam, I got 17 score for Set B, because some of the questions
                    are
                    not complete especially from test 2 number 1, the only en_core_web_lg is the one that I answered but
                    I think it is wrong, and also from test 3 number 3, I honestly don't know the answer.
                </p>

                <div class="exam-score">
                    <p style="font-size: 1.2em; margin-top: 15px; color: #ffffff;">Midterm Exam Grade: <span
                            style="color: #4CAF50; font-weight: bold;">17</span></p>
                </div>

            </div>

        </section>
        <br>
        <br>
        <section class="activity-card">
            <h2 style="color: #ffffff; text-align: center;">Prelim Term Exam Set B</h2>

            <h2 style="color: #ffffff; text-align: center;">Answer</h2>
            <div class="image-container" style="display: flex; justify-content: space-between; margin: 20px 0;">
                <img src="D:\cursor\picture\img20241207_13512274.png" alt="Portfolio Screenshot 1"
                    style="width: 500px; height: 500px; border-radius: 5%; margin-right: 20px;">
                <img src="D:\cursor\picture\img20241207_13533858.png" alt="Portfolio Screenshot 2"
                    style="width: 500px; height: 500px; border-radius: 5%; margin-right: 20px;">
                <img src="D:\cursor\picture\img20241207_13551974.png" alt="Portfolio Screenshot 2"
                    style="width: 500px; height: 500px; border-radius: 5%; margin-right: 20px;">

            </div>
            <div class="image-container" style="display: flex; justify-content: center; margin: 20px 0;">
                <img src="D:\cursor\picture\img20241207_14001236.png" alt="Portfolio Screenshot 2"
                    style="width: 355px; height: 500px; border-radius: 5%; margin: 0 auto;">
            </div>
        </section>
    </div>
</div>

<link rel="stylesheet" href="styles/project1.css">
<script src="scripts/project1.js" defer></script>
<script>
    function uploadFile(inputId) {
        const fileInput = document.getElementById(inputId);
        const file = fileInput.files[0];

        if (file) {
            // Here you would typically send the file to your server
            alert(`File selected: ${file.name}`);
            // Add your file upload logic here
        } else {
            alert('Please select a file first');
        }
    }
</script>